{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I guess beta is: [-2.33380423  4.49586808  9.30021044]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "def noisy_line(x, noise):\n",
    "    #print x.shape\n",
    "    assert len(x.shape) == 1 and x.shape[0] == 2\n",
    "    beta = [-2.3, 4.5, 9.4]\n",
    "    x = np.append(x, [1])\n",
    "    return np.dot(beta, x) + noise\n",
    " \n",
    "class Regression:\n",
    "    def __init__(self):\n",
    "        self.learning_rate = 0.005\n",
    "        self.beta = np.zeros(3)\n",
    " \n",
    "    def learn(self, datum):\n",
    "        x_hat, target = datum\n",
    "        x_hat = np.append(x_hat, [1])\n",
    "        self.beta += self.delta_w(x_hat, target)\n",
    " \n",
    "    def delta_w(self, x_hat, target):\n",
    "        net = np.dot(x_hat, self.beta) # self.m * x_hat + self.b\n",
    "        #print net\n",
    "        return self.learning_rate * (target - net) * x_hat\n",
    " \n",
    " \n",
    "regresion_model = Regression()\n",
    " \n",
    "for _ in range(1000):\n",
    "    x_hat = np.random.uniform(-10, 10, size=(2,))\n",
    "    noise_hat = np.random.uniform(-1, 1)\n",
    "    y_hat = noisy_line(x_hat, noise_hat)\n",
    " \n",
    "    regresion_model.learn((x_hat, y_hat))\n",
    " \n",
    "print(\"I guess beta is: {}\".format(regresion_model.beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I guess beta is: [-2.33425164  4.49217319  9.36505604]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard\n",
    "import numpy as np\n",
    "\n",
    "writer = tf.summary.FileWriter(\"./tf_logsT3\", sess.graph)\n",
    "\n",
    "#beta = change vector\n",
    "#c = learning_rate\n",
    "#y_hat = target_val\n",
    "#net = sum_of_weighted_features\n",
    "#x_hat = input features\n",
    "\n",
    "x_hat = tf.placeholder(tf.float32, shape = [3,])\n",
    "y_hat = tf.placeholder(tf.float32, None)\n",
    "noise_hat = tf.placeholder(tf.float32, None)\n",
    "c = tf.constant(0.005, None)\n",
    "beta = tf.Variable([0.0, 0.0, 0.0], None)\n",
    "b = tf.constant([-2.3, 4.5, 9.4])\n",
    "\n",
    "generate_y = tf.reduce_sum(tf.multiply(x_hat, b))+ noise_hat\n",
    "\n",
    "#net = tf.matmul(x_hat, tf.reshape(beta, (3,1)), transpose_a = True) + noise_hat\n",
    "#print (x_hat.shape, \"x shape\", beta.shape, \"beta shape\")\n",
    "\n",
    "net = tf.reduce_sum(tf.multiply(x_hat, beta))\n",
    "be = beta.assign(beta + (c * (y_hat - net) * x_hat))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run( init )\n",
    "beta = b\n",
    "\n",
    "for i in range(1000):\n",
    "    x = np.random.uniform(-10, 10, size = 2)\n",
    "    x = np.append(x, [1])#.reshape((3,1))\n",
    "    noise = [np.random.uniform(-1,1)]\n",
    "    y = sess.run(generate_y, feed_dict = {x_hat: x, noise_hat: np.asarray(noise)})\n",
    "    net_a, ans_b = sess.run([net, be], feed_dict={x_hat: x, y_hat: y}) \n",
    "\n",
    "print(\"I guess beta is: {}\".format(ans_b))\n",
    "\n",
    "writer.close()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
